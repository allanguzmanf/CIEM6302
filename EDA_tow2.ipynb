{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "from ipyleaflet import Map, GeoJSON, GeoData, basemaps, LayersControl\n",
    "from shapely.geometry import Point, Polygon, LineString\n",
    "import dash\n",
    "from dash import dcc, html\n",
    "from dash.dependencies import Input, Output\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import folium\n",
    "import rasterio\n",
    "import rasterio.mask\n",
    "from rasterio.plot import reshape_as_image \n",
    "from rasterio.plot import reshape_as_raster\n",
    "from shapely.ops import unary_union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opening JSON file\n",
    "f = open('Rotterdam_data/historic_towages.json')\n",
    " \n",
    "# returns JSON object as a dictionary\n",
    "tow_data = json.load(f)\n",
    " \n",
    "# Closing file\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create empty lists to store tugs data and their original JSON index\n",
    "# tugs_data = []\n",
    "# original_index = []\n",
    "\n",
    "# # Extract tugs data into a separate list and store their original index\n",
    "# for i, item in enumerate(tow_data):\n",
    "#     for tug in item['tugs']:\n",
    "#         tugs_data.append(tug)\n",
    "#         original_index.append(i)\n",
    "\n",
    "# # Create a DataFrame for tugs data with the original index\n",
    "# tugs_df = pd.DataFrame(tugs_data)\n",
    "# tugs_df['original_index'] = original_index  # Add original index as a new column\n",
    "\n",
    "\n",
    "# # Create a DataFrame for the rest of the data\n",
    "# vessel_data = [{'from': item['from'],\n",
    "#                'to': item['to'],\n",
    "#                'vessel': item['vessel'],\n",
    "#                'type': item['type'],\n",
    "#                'additional_data': item['additional_data']}\n",
    "#               for item in tow_data]\n",
    "\n",
    "# vessel_df = pd.DataFrame(vessel_data)\n",
    "\n",
    "# # Display the DataFrames\n",
    "# tugs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create empty lists to store tugs data and their original JSON index\n",
    "tugs_datab = []\n",
    "original_indexb = []\n",
    "vessel_name = []  # Create a list to store previous vessel names\n",
    "vessel_mmsi = []  # Create a list to store previous vessel names\n",
    "\n",
    "\n",
    "# Extract tugs data into a separate list, store their original index, and the previous vessel name\n",
    "for i, item in enumerate(tow_data):\n",
    "    for tug in item['tugs']:\n",
    "        tugs_datab.append(tug)\n",
    "        original_indexb.append(i)\n",
    "        vessel_name.append(item['vessel']['name'])\n",
    "        vessel_mmsi.append(item['vessel']['mmsi'])\n",
    "\n",
    "\n",
    "# Create a DataFrame for tugs data with the original index and previous vessel name\n",
    "tugs_dfb = pd.DataFrame(tugs_datab)\n",
    "tugs_dfb['original_index'] = original_indexb  # Add original index as a new column\n",
    "tugs_dfb['vessel_name'] = vessel_name  # Add vessel name as a new column\n",
    "tugs_dfb['vessel_mmsi'] = vessel_mmsi\n",
    "\n",
    "\n",
    "# Create a DataFrame for the rest of the data (excluding tugs)\n",
    "vessel_datab = [{'from': item['from'],\n",
    "               'to': item['to'],\n",
    "               'vessel': item['vessel'],\n",
    "               'type': item['type'],\n",
    "               'additional_data': item['additional_data']}\n",
    "              for item in tow_data]\n",
    "\n",
    "vessel_dfb = pd.DataFrame(vessel_datab)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tugs_dfb = tugs_dfb.merge(vessel_dfb['type'], left_on='original_index', right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tugs_incoming = tugs_dfb[tugs_dfb['type']=='incoming']\n",
    "tugs_incoming = tugs_incoming[['from',\t'to',\t'from_location' ,'to_haven', 'original_index']]\n",
    "\n",
    "# Create a Shapely Point geometry from the \"from_location\" coordinates\n",
    "tugs_incoming['geometry'] = tugs_incoming['from_location'].apply(lambda coord: Point(coord))\n",
    "\n",
    "# Convert the DataFrame to a GeoDataFrame\n",
    "tugs_incoming_gdf = gpd.GeoDataFrame(tugs_incoming, geometry='geometry')\n",
    "tugs_incoming_gdf = tugs_incoming_gdf.set_crs(\"EPSG:4326\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tugs_dfb[['from_long', 'from_lat']] = tugs_dfb['from_location'].apply(lambda x: pd.Series(str(x).strip('[]').split(','))).astype(float)\n",
    "tugs_dfb[['to_long', 'to_lat']] = tugs_dfb['to_location'].apply(lambda x: pd.Series(str(x).strip('[]').split(','))).astype(float)\n",
    "tugs_dfb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import other info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_dict(d, parent_key='', sep='_'):\n",
    "    items = {}\n",
    "    for k, v in d.items():\n",
    "        new_key = f\"{parent_key}{sep}{k}\" if parent_key else k\n",
    "        if isinstance(v, dict):\n",
    "            items.update(flatten_dict(v, new_key, sep=sep))\n",
    "        else:\n",
    "            items[new_key] = v\n",
    "    return items\n",
    "\n",
    "# Opening JSON file\n",
    "f = open('Rotterdam_data/ais_rotterdam/ais_rotterdam_6.json')\n",
    " \n",
    "# returns JSON object as a dictionary\n",
    "data = json.load(f)\n",
    " \n",
    "# Flatten each dictionary and store the results in a list\n",
    "flattened_dicts = [flatten_dict(d) for d in data['data']]\n",
    "\n",
    "# Create a DataFrame\n",
    "data = pd.DataFrame(flattened_dicts)\n",
    "\n",
    "# Closing file\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #data['navigation_destination_eta'] = pd.to_datetime(data['navigation_destination_eta'])\n",
    "# #data['navigation_time'] = pd.to_datetime(data['navigation_time'])\n",
    "# # Remove rows where 'vessel_type' is 'tug'\n",
    "# data = data[data['vessel_type'] != 'tug']\n",
    "# # Remove the 'vessel_subtype' column\n",
    "# data = data.drop('vessel_subtype', 'vessel_callsign','navigation_status', 'navigation_destination_eta', 'navigation_heading', 'navigation_time', 'navigation_course', 'navigation_speed\t', 'navigation_location_type', 'navigation_location_coordinates')\n",
    "# #data[['navigation_location_lat', 'navigation_location_long']] = data['navigation_location_coordinates'].apply(lambda x: pd.Series(str(x).strip('[]').split(','))).astype(float)\n",
    "# data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_drop = [\n",
    "    'vessel_callsign',\n",
    "    'navigation_heading',\n",
    "    'navigation_course',\n",
    "    'navigation_speed',\n",
    "    'navigation_location_type',\n",
    "]\n",
    "\n",
    "numeric_columns = [\n",
    "    'device_mmsi',\n",
    "    'device_dimensions_to_bow',           \n",
    "    'device_dimensions_to_stern',       \n",
    "    'device_dimensions_to_starboard',     \n",
    "    'device_dimensions_to_port',\n",
    "    #'vessel_imo'\n",
    "    'navigation_draught',\n",
    "    #'vessel_type',\n",
    "    #'vessel_subtype'\n",
    "]\n",
    "\n",
    "info_columns = [\n",
    "    'device_mmsi',\n",
    "    'vessel_type',\n",
    "    #'vessel_subtype'\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vessel_size = data[numeric_columns]\n",
    "vessel_size = vessel_size.groupby('device_mmsi').median()\n",
    "vessel_size['length'] = vessel_size['device_dimensions_to_bow'] + vessel_size['device_dimensions_to_stern']\n",
    "vessel_size['width'] = vessel_size['device_dimensions_to_starboard'] + vessel_size['device_dimensions_to_port']\n",
    "vessel_size.drop(['device_dimensions_to_bow','device_dimensions_to_stern', 'device_dimensions_to_starboard' ,'device_dimensions_to_port'], axis=1, inplace=True)\n",
    "vessel_size.reset_index(inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vessel_info = data[info_columns]\n",
    "\n",
    "vessel_info = vessel_info.groupby('device_mmsi').agg(lambda x: x.mode(0))\n",
    "vessel_info.reset_index(inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vessel_data = pd.merge(vessel_size,vessel_info)\n",
    "vessel_data['vessel_type_Code'], unique_values = pd.factorize(vessel_data['vessel_type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_db = pd.merge(tugs_dfb,vessel_data,how= 'right',left_on='vessel_mmsi',right_on='device_mmsi')\n",
    "main_db.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from geopy.distance import geodesic\n",
    "import folium\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Assuming 'column_name' is the name of the column containing strings in your DataFrame\n",
    "label_encoder = LabelEncoder()\n",
    "main_db['Incoming to'] = label_encoder.fit_transform(main_db['to_berth'])\n",
    "main_db\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the \"from\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define categorical and numeric columns\n",
    "#categorical_cols = ['vessel_type', 'vessel_callsign', 'vessel_subtype', 'vessel_name', 'navigation_status']\n",
    "features = ['navigation_draught', \n",
    "            'length',\t\n",
    "            'width',  \n",
    "            'vessel_type_Code', \n",
    "            'Incoming to']\n",
    "\n",
    "X = main_db[features].values\n",
    "\n",
    "# Assuming 'latitude' and 'longitude' are your target variables (y-values)\n",
    "# Target variables \n",
    "y_from_lat = main_db['to_lat'].values\n",
    "y_from_lon = main_db['to_long'].values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and testing sets for latitude prediction\n",
    "X_from_lat_train, X_from_lat_test, y_from_lat_train, y_from_lat_test = train_test_split(X, y_from_lat, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize and train the linear regression model for latitude\n",
    "linear_model_lat = LinearRegression()\n",
    "linear_model_lat.fit(X_from_lat_train, y_from_lat_train)\n",
    "\n",
    "# Make predictions for latitude\n",
    "predictions_lat = linear_model_lat.predict(X_from_lat_test)\n",
    "\n",
    "# Calculate mean squared error for latitude prediction\n",
    "mse_lat = mean_squared_error(y_from_lat_test, predictions_lat)\n",
    "print(f\"Linear Regression Mean Squared Error (Latitude): {mse_lat}\")\n",
    "\n",
    "# Split data into training and testing sets for longitude prediction\n",
    "X_from_lon_train, X_from_lon_test, y_from_lon_train, y_from_lon_test = train_test_split(X, y_from_lon, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize and train the linear regression model for longitude\n",
    "linear_model_lon = LinearRegression()\n",
    "linear_model_lon.fit(X_from_lon_train, y_from_lon_train)\n",
    "\n",
    "# Make predictions for longitude\n",
    "predictions_lon = linear_model_lon.predict(X_from_lon_test)\n",
    "\n",
    "# Calculate mean squared error for longitude prediction\n",
    "mse_lon = mean_squared_error(y_from_lon_test, predictions_lon)\n",
    "print(f\"Linear Regression Mean Squared Error (Longitude): {mse_lon}\")\n",
    "\n",
    "# Calculate geodesic distance between true and predicted coordinates in meters\n",
    "geodesic_distances = []\n",
    "for i in range(len(predictions_lat)):\n",
    "    true_coords = (y_from_lat_test[i], y_from_lon_test[i])\n",
    "    pred_coords = (predictions_lat[i], predictions_lon[i])\n",
    "    distance = geodesic(true_coords, pred_coords).meters\n",
    "    geodesic_distances.append(distance)\n",
    "    print(f\"Geodesic Distance (meter) for Test Point {i+1}: {distance}\")\n",
    "\n",
    "# Calculate average geodesic distance\n",
    "total_distance = np.sum(geodesic_distances)\n",
    "average_distance = total_distance / len(geodesic_distances)\n",
    "print(f\"Average Geodesic Distance: {average_distance} meters\")\n",
    "\n",
    "# Create a map centered at a specific location (e.g., mean latitude and longitude of your data)\n",
    "# Define the latitude and longitude to center the map\n",
    "center_latitude = 51.9775\n",
    "center_longitude = 4.1331\n",
    "\n",
    "# Create a map centered at the specified location\n",
    "map_center = [center_latitude, center_longitude]\n",
    "a = folium.Map(location=map_center, zoom_start=12)\n",
    "\n",
    "# Add real and predicted locations to the map for the first 3 results\n",
    "for i in range(1):\n",
    "    true_coords = (y_from_lat_test[i], y_from_lon_test[i])\n",
    "    pred_coords = (predictions_lat[i], predictions_lon[i])\n",
    "    folium.Marker(location=true_coords, popup=f'Real: {true_coords}', icon=folium.Icon(color='green')).add_to(a)\n",
    "    folium.Marker(location=pred_coords, popup=f'Predicted: {pred_coords}', icon=folium.Icon(color='blue')).add_to(a)\n",
    "\n",
    "# Save the map as an HTML files\n",
    "a.save('map_linear_regression.html')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "\n",
    "# Your previous code for creating the map\n",
    "display(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize and train the decision tree regression model for latitude\n",
    "decision_tree_lat = DecisionTreeRegressor(random_state=42)\n",
    "decision_tree_lat.fit(X_from_lat_train, y_from_lat_train)\n",
    "\n",
    "# Make predictions for latitude\n",
    "predictions_lat = decision_tree_lat.predict(X_from_lat_test)\n",
    "\n",
    "# Calculate mean squared error for latitude prediction\n",
    "mse_lat = mean_squared_error(y_from_lat_test, predictions_lat)\n",
    "print(f\"Decision Tree Mean Squared Error (Latitude): {mse_lat}\")\n",
    "\n",
    "# Initialize and train the decision tree regression model for longitude\n",
    "decision_tree_lon = DecisionTreeRegressor(random_state=42)\n",
    "decision_tree_lon.fit(X_from_lon_train, y_from_lon_train)\n",
    "\n",
    "# Make predictions for longitude\n",
    "predictions_lon = decision_tree_lon.predict(X_from_lon_test)\n",
    "\n",
    "# Calculate mean squared error for longitude prediction\n",
    "mse_lon = mean_squared_error(y_from_lon_test, predictions_lon)\n",
    "print(f\"Decision Tree Mean Squared Error (Longitude): {mse_lon}\")\n",
    "\n",
    "# Calculate geodesic distance between true and predicted coordinates in meters\n",
    "geodesic_distances = []\n",
    "for i in range(len(predictions_lat)):\n",
    "    true_coords = (y_from_lat_test[i], y_from_lon_test[i])\n",
    "    pred_coords = (predictions_lat[i], predictions_lon[i])\n",
    "    distance = geodesic(true_coords, pred_coords).meters\n",
    "    geodesic_distances.append(distance)\n",
    "    print(f\"Geodesic Distance (meter) for Test Point {i+1}: {distance}\")\n",
    "\n",
    "# Calculate average geodesic distance\n",
    "total_distance = np.sum(geodesic_distances)\n",
    "average_distance = total_distance / len(geodesic_distances)\n",
    "print(f\"Average Geodesic Distance: {average_distance} meters\")\n",
    "\n",
    "# Define the latitude and longitude to center the map\n",
    "center_latitude = 51.9775\n",
    "center_longitude = 4.1331\n",
    "\n",
    "# Create a map centered at the specified location\n",
    "map_center = [center_latitude, center_longitude]\n",
    "b = folium.Map(location=map_center, zoom_start=12)\n",
    "\n",
    "# Add real and predicted locations to the map for the first 3 results\n",
    "for i in range(1):\n",
    "    true_coords = (y_from_lat_test[i], y_from_lon_test[i])\n",
    "    pred_coords = (predictions_lat[i], predictions_lon[i])\n",
    "    folium.Marker(location=true_coords, popup=f'Real: {true_coords}', icon=folium.Icon(color='green')).add_to(b)\n",
    "    folium.Marker(location=pred_coords, popup=f'Predicted: {pred_coords}', icon=folium.Icon(color='blue')).add_to(b)\n",
    "\n",
    "# Save the map as an HTML file\n",
    "b.save('map_decision_tree.html')\n",
    "display(b)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize and train the random forest regression model for latitude\n",
    "random_forest_lat = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "random_forest_lat.fit(X_from_lat_train, y_from_lat_train)\n",
    "\n",
    "# Make predictions for latitude\n",
    "predictions_lat = random_forest_lat.predict(X_from_lat_test)\n",
    "\n",
    "# Calculate mean squared error for latitude prediction\n",
    "mse_lat = mean_squared_error(y_from_lat_test, predictions_lat)\n",
    "print(f\"Random Forest Mean Squared Error (Latitude): {mse_lat}\")\n",
    "\n",
    "# Initialize and train the random forest regression model for longitude\n",
    "random_forest_lon = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "random_forest_lon.fit(X_from_lon_train, y_from_lon_train)\n",
    "\n",
    "# Make predictions for longitude\n",
    "predictions_lon = random_forest_lon.predict(X_from_lon_test)\n",
    "\n",
    "# Calculate mean squared error for longitude prediction\n",
    "mse_lon = mean_squared_error(y_from_lon_test, predictions_lon)\n",
    "print(f\"Random Forest Mean Squared Error (Longitude): {mse_lon}\")\n",
    "\n",
    "# Calculate geodesic distance between true and predicted coordinates in meters\n",
    "geodesic_distances = []\n",
    "for i in range(len(predictions_lat)):\n",
    "    true_coords = (y_from_lat_test[i], y_from_lon_test[i])\n",
    "    pred_coords = (predictions_lat[i], predictions_lon[i])\n",
    "    distance = geodesic(true_coords, pred_coords).meters\n",
    "    geodesic_distances.append(distance)\n",
    "    print(f\"Geodesic Distance (meter) for Test Point {i+1}: {distance}\")\n",
    "\n",
    "# Calculate average geodesic distance\n",
    "total_distance = np.sum(geodesic_distances)\n",
    "average_distance = total_distance / len(geodesic_distances)\n",
    "print(f\"Average Geodesic Distance: {average_distance} meters\")\n",
    "\n",
    "# Define the latitude and longitude to center the map\n",
    "center_latitude = 51.9775\n",
    "center_longitude = 4.1331\n",
    "\n",
    "# Create a map centered at the specified location\n",
    "map_center = [center_latitude, center_longitude]\n",
    "c = folium.Map(location=map_center, zoom_start=12)\n",
    "\n",
    "# Add real and predicted locations to the map for the first 3 results\n",
    "for i in range(1):\n",
    "    true_coords = (y_from_lat_test[i], y_from_lon_test[i])\n",
    "    pred_coords = (predictions_lat[i], predictions_lon[i])\n",
    "    folium.Marker(location=true_coords, popup=f'Real: {true_coords}', icon=folium.Icon(color='green')).add_to(c)\n",
    "    folium.Marker(location=pred_coords, popup=f'Predicted: {pred_coords}', icon=folium.Icon(color='blue')).add_to(c)\n",
    "\n",
    "# Save the map as an HTML file\n",
    "c.save('map_random_forest.html')\n",
    "display(c)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradient Boosting Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize and train the gradient boosting regression model for latitude\n",
    "gradient_boosting_lat = GradientBoostingRegressor(n_estimators=100, random_state=42)\n",
    "gradient_boosting_lat.fit(X_from_lat_train, y_from_lat_train)\n",
    "\n",
    "# Make predictions for latitude\n",
    "predictions_lat = gradient_boosting_lat.predict(X_from_lat_test)\n",
    "\n",
    "# Initialize and train the gradient boosting regression model for longitude\n",
    "gradient_boosting_lon = GradientBoostingRegressor(n_estimators=100, random_state=42)\n",
    "gradient_boosting_lon.fit(X_from_lon_train, y_from_lon_train)\n",
    "\n",
    "# Make predictions for longitude\n",
    "predictions_lon = gradient_boosting_lon.predict(X_from_lon_test)\n",
    "\n",
    "# Calculate geodesic distance between true and predicted coordinates in meters\n",
    "geodesic_distances = []\n",
    "for i in range(len(predictions_lat)):\n",
    "    true_coords = (y_from_lat_test[i], y_from_lon_test[i])\n",
    "    pred_coords = (predictions_lat[i], predictions_lon[i])\n",
    "    distance = geodesic(true_coords, pred_coords).meters\n",
    "    geodesic_distances.append(distance)\n",
    "    print(f\"Geodesic Distance (meter) for Test Point {i+1}: {distance}\")\n",
    "\n",
    "# Calculate average geodesic distance\n",
    "total_distance = np.sum(geodesic_distances)\n",
    "average_distance = total_distance / len(geodesic_distances)\n",
    "print(f\"Average Geodesic Distance: {average_distance} meters\")\n",
    "\n",
    "# Define the latitude and longitude to center the map\n",
    "center_latitude = 51.9775\n",
    "center_longitude = 4.1331\n",
    "\n",
    "# Create a map centered at the specified location\n",
    "map_center = [center_latitude, center_longitude]\n",
    "d = folium.Map(location=map_center, zoom_start=12)\n",
    "\n",
    "# Add real and predicted locations to the map for the first 3 results\n",
    "for i in range(1):  # You can change this to display more or fewer points\n",
    "    true_coords = (y_from_lat_test[i], y_from_lon_test[i])\n",
    "    pred_coords = (predictions_lat[i], predictions_lon[i])\n",
    "    folium.Marker(location=true_coords, popup=f'Real: {true_coords}', icon=folium.Icon(color='green')).add_to(d)\n",
    "    folium.Marker(location=pred_coords, popup=f'Predicted: {pred_coords}', icon=folium.Icon(color='blue')).add_to(d)\n",
    "\n",
    "# Save the map as an HTML file\n",
    "d.save('map_gradient_boosting.html')\n",
    "display(d)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "\n",
    "# Initialize and train the XGBoost regression model for latitude\n",
    "xgb_lat = XGBRegressor(n_estimators=100, random_state=42)\n",
    "xgb_lat.fit(X_from_lat_train, y_from_lat_train)\n",
    "\n",
    "# Make predictions for latitude\n",
    "predictions_lat = xgb_lat.predict(X_from_lat_test)\n",
    "\n",
    "# Initialize and train the XGBoost regression model for longitude\n",
    "xgb_lon = XGBRegressor(n_estimators=100, random_state=42)\n",
    "xgb_lon.fit(X_from_lon_train, y_from_lon_train)\n",
    "\n",
    "# Make predictions for longitude\n",
    "predictions_lon = xgb_lon.predict(X_from_lon_test)\n",
    "\n",
    "# Calculate geodesic distance between true and predicted coordinates in meters\n",
    "geodesic_distances = []\n",
    "for i in range(len(predictions_lat)):\n",
    "    true_coords = (y_from_lat_test[i], y_from_lon_test[i])\n",
    "    pred_coords = (predictions_lat[i], predictions_lon[i])\n",
    "    distance = geodesic(true_coords, pred_coords).meters\n",
    "    geodesic_distances.append(distance)\n",
    "    print(f\"Geodesic Distance (meter) for Test Point {i+1}: {distance}\")\n",
    "\n",
    "# Calculate average geodesic distance\n",
    "total_distance = np.sum(geodesic_distances)\n",
    "average_distance = total_distance / len(geodesic_distances)\n",
    "print(f\"Average Geodesic Distance: {average_distance} meters\")\n",
    "\n",
    "# Define the latitude and longitude to center the map\n",
    "center_latitude = 51.9775\n",
    "center_longitude = 4.1331\n",
    "\n",
    "# Create a map centered at the specified location\n",
    "map_center = [center_latitude, center_longitude]\n",
    "xgb_map = folium.Map(location=map_center, zoom_start=12)\n",
    "\n",
    "# Add real and predicted locations to the map for the first 3 results\n",
    "for i in range(1):  # You can change this to display more or fewer points\n",
    "    true_coords = (y_from_lat_test[i], y_from_lon_test[i])\n",
    "    pred_coords = (predictions_lat[i], predictions_lon[i])\n",
    "    folium.Marker(location=true_coords, popup=f'Real: {true_coords}', icon=folium.Icon(color='green')).add_to(xgb_map)\n",
    "    folium.Marker(location=pred_coords, popup=f'Predicted: {pred_coords}', icon=folium.Icon(color='blue')).add_to(xgb_map)\n",
    "\n",
    "# Save the map as an HTML file\n",
    "xgb_map.save('map_xgboost.html')\n",
    "display(xgb_map)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "import folium\n",
    "\n",
    "# Create a KMeans clusterer for latitude and longitude\n",
    "kmeans = KMeans(n_clusters=3, random_state=42)  # Change the number of clusters as needed\n",
    "clusters = kmeans.fit_predict(X)\n",
    "\n",
    "# Add cluster labels to the original dataframe\n",
    "data['cluster'] = clusters\n",
    "\n",
    "# Define the latitude and longitude to center the map\n",
    "center_latitude = data['Latitude'].mean()\n",
    "center_longitude = data['Longitude'].mean()\n",
    "\n",
    "# Create a map centered at the specified location\n",
    "map_center = [center_latitude, center_longitude]\n",
    "kmeans_map = folium.Map(location=map_center, zoom_start=12)\n",
    "\n",
    "# Add clustered points to the map\n",
    "for cluster in set(clusters):\n",
    "    cluster_data = data[data['cluster'] == cluster]\n",
    "    for index, row in cluster_data.iterrows():\n",
    "        folium.Marker(location=[row['Latitude'], row['Longitude']], popup=f'Cluster {cluster}', icon=folium.Icon(color='blue')).add_to(kmeans_map)\n",
    "\n",
    "# Save the map as an HTML file\n",
    "kmeans_map.save('map_kmeans.html')\n",
    "display(kmeans_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "# Create a DBScan clusterer for latitude and longitude\n",
    "dbscan = DBSCAN(eps=0.1, min_samples=5)\n",
    "clusters = dbscan.fit_predict(X)\n",
    "\n",
    "# Add cluster labels to the original dataframe\n",
    "data['cluster'] = clusters\n",
    "\n",
    "# Define the latitude and longitude to center the map\n",
    "center_latitude = data['Latitude'].mean()\n",
    "center_longitude = data['Longitude'].mean()\n",
    "\n",
    "# Create a map centered at the specified location\n",
    "map_center = [center_latitude, center_longitude]\n",
    "dbscan_map = folium.Map(location=map_center, zoom_start=12)\n",
    "\n",
    "# Add clustered points to the map\n",
    "for cluster in set(clusters):\n",
    "    cluster_data = data[data['cluster'] == cluster]\n",
    "    for index, row in cluster_data.iterrows():\n",
    "        folium.Marker(location=[row['Latitude'], row['Longitude']], popup=f'Cluster {cluster}', icon=folium.Icon(color='blue')).add_to(dbscan_map)\n",
    "\n",
    "# Save the map as an HTML file\n",
    "dbscan_map.save('map_dbscan.html')\n",
    "display(dbscan_map)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CIEM6302",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
